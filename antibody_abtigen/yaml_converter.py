"""
CIF to Boltz-1 YAML converter module.

This module converts PDB/CIF structure files to YAML configuration files
for Boltz-1 based structure prediction/generation tools.

Key features:
1. Extracts full sequences from _entity_poly.pdbx_seq_one_letter_code
2. Extracts disulfide bond information from _struct_conn
3. Preserves chain topology (Fab = 2 chains, scFv = 1 chain)
"""

import os
import json
import re
from pathlib import Path
from typing import Optional, List, Dict, Tuple, Any

try:
    import gemmi
    GEMMI_AVAILABLE = True
except ImportError:
    GEMMI_AVAILABLE = False

try:
    import yaml
    YAML_AVAILABLE = True
except ImportError:
    YAML_AVAILABLE = False


def check_dependencies():
    """Check if required dependencies are available."""
    missing = []
    if not GEMMI_AVAILABLE:
        missing.append("gemmi")
    if not YAML_AVAILABLE:
        missing.append("pyyaml")

    if missing:
        raise ImportError(
            f"Missing dependencies: {', '.join(missing)}. "
            f"Install with: pip install {' '.join(missing)}"
        )


def extract_sequences_from_cif(cif_path: str) -> List[Dict[str, Any]]:
    """
    Extract sequences from CIF file.

    First tries _entity_poly.pdbx_seq_one_letter_code for full sequences.
    Falls back to extracting from _atom_site coordinates if entity_poly is not available.

    Args:
        cif_path: Path to CIF file

    Returns:
        List of dicts with chain info: {entity_id, chain_ids, sequence, type}
    """
    check_dependencies()

    doc = gemmi.cif.read(cif_path)
    block = doc.sole_block()

    sequences = []

    # Try to get entity_poly information (full sequences) first
    entity_poly = block.find(['_entity_poly.entity_id',
                              '_entity_poly.pdbx_seq_one_letter_code',
                              '_entity_poly.pdbx_strand_id',
                              '_entity_poly.type'])

    if len(entity_poly) > 0:
        # Use entity_poly if available
        for row in entity_poly:
            entity_id = row[0]
            raw_seq = row[1] if row[1] else ""
            strand_ids = row[2] if row[2] else ""
            poly_type = row[3] if row[3] else "polypeptide(L)"

            seq = clean_sequence(raw_seq)
            chain_ids = [c.strip() for c in strand_ids.split(',') if c.strip()]

            sequences.append({
                'entity_id': entity_id,
                'chain_ids': chain_ids,
                'sequence': seq,
                'type': poly_type
            })
    else:
        # Fall back to extracting from atom_site coordinates
        sequences = extract_sequences_from_coordinates(cif_path)

    return sequences


def extract_sequences_from_coordinates(cif_path: str) -> List[Dict[str, Any]]:
    """
    Extract sequences from CIF file using _atom_site coordinates.

    This is a fallback when _entity_poly is not available (e.g., for CIF files
    generated by Biopython's MMCIFIO).

    Args:
        cif_path: Path to CIF file

    Returns:
        List of dicts with chain info: {entity_id, chain_ids, sequence, type}
    """
    # Use gemmi's Structure class for easier chain/residue iteration
    structure = gemmi.read_structure(cif_path)

    sequences = []

    # 3-letter to 1-letter amino acid code mapping
    aa_map = {
        'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',
        'GLN': 'Q', 'GLU': 'E', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',
        'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',
        'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V',
        # Modified amino acids
        'MSE': 'M',  # Selenomethionine
        'PTR': 'Y',  # Phosphotyrosine
        'SEP': 'S',  # Phosphoserine
        'TPO': 'T',  # Phosphothreonine
        'CSO': 'C',  # S-hydroxycysteine
        'HYP': 'P',  # Hydroxyproline
        'MLY': 'K',  # N-dimethyl-lysine
        'PCA': 'E',  # Pyroglutamic acid
    }

    for model in structure:
        for chain in model:
            chain_id = chain.name
            residues = []

            for residue in chain:
                # Skip non-protein residues (water, ligands, etc.)
                if residue.name in aa_map:
                    residues.append((residue.seqid.num, aa_map[residue.name]))
                elif len(residue.name) == 3 and residue.name.isalpha():
                    # Unknown amino acid, use X
                    residues.append((residue.seqid.num, 'X'))

            if residues:
                # Sort by residue number and extract sequence
                residues.sort(key=lambda x: x[0])
                sequence = ''.join([r[1] for r in residues])

                sequences.append({
                    'entity_id': chain_id,
                    'chain_ids': [chain_id],
                    'sequence': sequence,
                    'type': 'polypeptide(L)'
                })

        # Only process the first model
        break

    return sequences


def clean_sequence(raw_seq: str) -> str:
    """
    Clean sequence string from CIF format.

    Handles:
    - Newlines and whitespace
    - Parenthesized modified residues like (MSE) -> M
    - Non-standard characters
    """
    # Remove newlines and extra whitespace
    seq = raw_seq.replace('\n', '').replace(' ', '')

    # Handle modified residues in parentheses
    # Common ones: (MSE) -> M (selenomethionine), (PTR) -> Y, etc.
    modified_residue_map = {
        'MSE': 'M',  # Selenomethionine
        'PTR': 'Y',  # Phosphotyrosine
        'SEP': 'S',  # Phosphoserine
        'TPO': 'T',  # Phosphothreonine
        'CSO': 'C',  # S-hydroxycysteine
        'HYP': 'P',  # Hydroxyproline
        'MLY': 'K',  # N-dimethyl-lysine
        'PCA': 'E',  # Pyroglutamic acid
    }

    # Replace (XXX) with single letter code
    def replace_modified(match):
        code = match.group(1)
        return modified_residue_map.get(code, 'X')

    seq = re.sub(r'\(([A-Z]{3})\)', replace_modified, seq)

    # Remove any remaining non-standard characters
    seq = ''.join(c for c in seq if c.isalpha() and c.isupper())

    return seq


def extract_disulfide_bonds(cif_path: str) -> List[Dict[str, Any]]:
    """
    Extract disulfide bond information from CIF file.

    Args:
        cif_path: Path to CIF file

    Returns:
        List of disulfide bonds with chain and residue info
    """
    check_dependencies()

    doc = gemmi.cif.read(cif_path)
    block = doc.sole_block()

    bonds = []

    # Find struct_conn table
    struct_conn = block.find(['_struct_conn.conn_type_id',
                              '_struct_conn.ptnr1_label_asym_id',
                              '_struct_conn.ptnr1_label_seq_id',
                              '_struct_conn.ptnr1_label_comp_id',
                              '_struct_conn.ptnr2_label_asym_id',
                              '_struct_conn.ptnr2_label_seq_id',
                              '_struct_conn.ptnr2_label_comp_id'])

    for row in struct_conn:
        conn_type = row[0]
        if conn_type and conn_type.lower() == 'disulf':
            bond = {
                'chain1': row[1],
                'resnum1': int(row[2]) if row[2] and row[2].isdigit() else None,
                'resname1': row[3],
                'chain2': row[4],
                'resnum2': int(row[5]) if row[5] and row[5].isdigit() else None,
                'resname2': row[6],
                'type': 'disulfide'
            }
            if bond['resnum1'] is not None and bond['resnum2'] is not None:
                bonds.append(bond)

    return bonds


def build_residue_index_map(cif_path: str) -> Dict[Tuple[str, int], int]:
    """
    Build a mapping from (chain_id, residue_number) to sequence index (0-based).

    This is needed to convert PDB residue numbers to sequence indices for bonds.

    Args:
        cif_path: Path to CIF file

    Returns:
        Dict mapping (chain_id, resnum) -> sequence_index
    """
    check_dependencies()

    doc = gemmi.cif.read(cif_path)
    block = doc.sole_block()

    index_map = {}

    # Get atom_site to find the mapping
    # We need label_asym_id (chain), label_seq_id (seq position)
    atom_site = block.find(['_atom_site.label_asym_id',
                            '_atom_site.label_seq_id',
                            '_atom_site.label_atom_id'])

    seen = set()
    for row in atom_site:
        chain_id = row[0]
        seq_id = row[1]

        if seq_id and seq_id.isdigit():
            key = (chain_id, int(seq_id))
            if key not in seen:
                # seq_id in CIF is typically 1-based, convert to 0-based index
                index_map[key] = int(seq_id) - 1
                seen.add(key)

    return index_map


def convert_bonds_to_indices(
    bonds: List[Dict[str, Any]],
    sequences: List[Dict[str, Any]],
    index_map: Dict[Tuple[str, int], int]
) -> List[List[int]]:
    """
    Convert disulfide bonds to Boltz format: [chain_idx, res_idx1, res_idx2].

    For intra-chain bonds: [chain_idx, res_idx1, res_idx2]
    For inter-chain bonds: Need special handling

    Args:
        bonds: List of bond dicts from extract_disulfide_bonds
        sequences: List of sequence dicts
        index_map: Mapping from (chain, resnum) to sequence index

    Returns:
        List of bond specifications in Boltz format
    """
    # Build chain_id to sequence index mapping
    chain_to_seq_idx = {}
    for i, seq_info in enumerate(sequences):
        for chain_id in seq_info['chain_ids']:
            chain_to_seq_idx[chain_id] = i

    boltz_bonds = []

    for bond in bonds:
        chain1 = bond['chain1']
        chain2 = bond['chain2']
        resnum1 = bond['resnum1']
        resnum2 = bond['resnum2']

        # Get sequence indices
        idx1 = index_map.get((chain1, resnum1))
        idx2 = index_map.get((chain2, resnum2))

        if idx1 is None or idx2 is None:
            continue

        seq_idx1 = chain_to_seq_idx.get(chain1)
        seq_idx2 = chain_to_seq_idx.get(chain2)

        if seq_idx1 is None or seq_idx2 is None:
            continue

        if seq_idx1 == seq_idx2:
            # Intra-chain bond: [chain_idx, res1, res2]
            boltz_bonds.append([seq_idx1, idx1, idx2])
        else:
            # Inter-chain bond: store as tuple for special handling
            # Format may vary by Boltz version
            boltz_bonds.append({
                'chain1': seq_idx1,
                'res1': idx1,
                'chain2': seq_idx2,
                'res2': idx2,
                'type': 'inter_chain_disulfide'
            })

    return boltz_bonds


def cif_to_boltz_yaml(
    cif_path: str,
    output_path: str,
    include_bonds: bool = True
) -> Dict[str, Any]:
    """
    Convert a CIF file to Boltz-1 YAML format.

    Args:
        cif_path: Path to input CIF file
        output_path: Path for output YAML file
        include_bonds: Whether to include disulfide bonds

    Returns:
        The generated YAML data dict
    """
    check_dependencies()

    # Extract sequences
    sequences = extract_sequences_from_cif(cif_path)

    # Build YAML structure
    yaml_data = {
        'version': 1,
        'sequences': []
    }

    for seq_info in sequences:
        # Only include protein sequences
        if 'polypeptide' in seq_info['type'].lower():
            # Use first chain ID as the identifier
            chain_id = seq_info['chain_ids'][0] if seq_info['chain_ids'] else seq_info['entity_id']

            yaml_data['sequences'].append({
                'protein': {
                    'id': chain_id,
                    'sequence': seq_info['sequence']
                }
            })

    # Extract and add bonds
    if include_bonds:
        bonds = extract_disulfide_bonds(cif_path)
        if bonds:
            index_map = build_residue_index_map(cif_path)
            boltz_bonds = convert_bonds_to_indices(bonds, sequences, index_map)

            # Filter to only include simple intra-chain bonds (list format)
            simple_bonds = [b for b in boltz_bonds if isinstance(b, list)]
            if simple_bonds:
                yaml_data['bonds'] = simple_bonds

    # Write YAML file
    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)

    with open(output_path, 'w') as f:
        yaml.dump(yaml_data, f, sort_keys=False, default_flow_style=False, allow_unicode=True)

    return yaml_data


def convert_datapoint_to_yamls(
    datapoint_dir: str,
    output_dir: str,
    include_bonds: bool = True
) -> Dict[str, str]:
    """
    Convert all CIF files in a data point directory to YAML files.

    Expected input structure:
        datapoint_dir/
        ├── DP_XXXX_Y_antibody.cif
        ├── DP_XXXX_Y_human_ag.cif
        └── DP_XXXX_Y_mouse_ag.cif

    Output structure:
        output_dir/
        ├── DP_XXXX_Y_antibody.yaml
        ├── DP_XXXX_Y_human_ag.yaml
        └── DP_XXXX_Y_mouse_ag.yaml

    Args:
        datapoint_dir: Path to data point directory
        output_dir: Path for output YAML files
        include_bonds: Whether to include disulfide bonds

    Returns:
        Dict mapping component name to output YAML path
    """
    check_dependencies()

    datapoint_path = Path(datapoint_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    results = {}

    # Find all CIF files
    cif_files = list(datapoint_path.glob('*.cif'))

    for cif_file in cif_files:
        # Generate output YAML path
        yaml_name = cif_file.stem + '.yaml'
        yaml_path = output_path / yaml_name

        try:
            cif_to_boltz_yaml(
                str(cif_file),
                str(yaml_path),
                include_bonds=include_bonds
            )

            # Determine component type from filename
            if 'antibody' in cif_file.stem:
                component = 'antibody'
            elif 'human_ag' in cif_file.stem:
                component = 'human_antigen'
            elif 'mouse_ag' in cif_file.stem:
                component = 'mouse_antigen'
            else:
                component = cif_file.stem

            results[component] = str(yaml_path)

        except Exception as e:
            print(f"Error converting {cif_file}: {e}")
            results[cif_file.stem] = f"ERROR: {e}"

    return results


def batch_convert_to_yamls(
    raw_data_dir: str,
    output_dir: str,
    include_bonds: bool = True,
    verbose: bool = True
) -> Dict[str, Dict[str, str]]:
    """
    Batch convert all data points to YAML files.

    Args:
        raw_data_dir: Directory containing DP_XXXX_Y folders
        output_dir: Output directory for YAML files
        include_bonds: Whether to include disulfide bonds
        verbose: Print progress

    Returns:
        Dict mapping datapoint ID to conversion results
    """
    check_dependencies()

    raw_path = Path(raw_data_dir)
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # Find all data point directories
    dp_dirs = sorted([d for d in raw_path.iterdir() if d.is_dir() and d.name.startswith('DP_')])

    if verbose:
        print(f"Found {len(dp_dirs)} data point directories")

    results = {}

    for dp_dir in dp_dirs:
        dp_id = dp_dir.name

        if verbose:
            print(f"Converting {dp_id}...")

        try:
            dp_results = convert_datapoint_to_yamls(
                str(dp_dir),
                str(output_path),
                include_bonds=include_bonds
            )
            results[dp_id] = dp_results

        except Exception as e:
            if verbose:
                print(f"  Error: {e}")
            results[dp_id] = {'error': str(e)}

    # Write summary
    summary_path = output_path / 'conversion_summary.json'
    with open(summary_path, 'w') as f:
        json.dump(results, f, indent=2)

    if verbose:
        success_count = sum(1 for r in results.values() if 'error' not in r)
        print(f"\nConversion complete: {success_count}/{len(results)} successful")
        print(f"Summary saved to: {summary_path}")

    return results


if __name__ == "__main__":
    import sys

    if len(sys.argv) < 3:
        print("Usage: python yaml_converter.py <input_cif> <output_yaml>")
        print("   or: python yaml_converter.py --batch <raw_dir> <output_dir>")
        sys.exit(1)

    if sys.argv[1] == '--batch':
        raw_dir = sys.argv[2]
        output_dir = sys.argv[3]
        batch_convert_to_yamls(raw_dir, output_dir)
    else:
        cif_path = sys.argv[1]
        output_path = sys.argv[2]
        result = cif_to_boltz_yaml(cif_path, output_path)
        print(f"Converted to {output_path}")
        print(f"Sequences: {len(result.get('sequences', []))}")
        print(f"Bonds: {len(result.get('bonds', []))}")
